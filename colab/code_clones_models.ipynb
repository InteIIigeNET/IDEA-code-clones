{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code-clones-models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaxVortman/IDEA-code-clones/blob/master/colab/code_clones_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvH-jD_u_Z8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy import sparse\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVN3aC5T_Z9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "def printMetrics(y_test, y_pred):\n",
        "    print('accuracy: ')\n",
        "    print(accuracy_score(y_test, y_pred))\n",
        "    print('\\nprecision: ')\n",
        "    print(precision_score(y_test, y_pred))\n",
        "    print('\\nrecall: ')\n",
        "    print(recall_score(y_test, y_pred))\n",
        "    print('\\nroc auc: ')\n",
        "    print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfwM70LzEj_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resample(X, y):\n",
        "  rus = RandomUnderSampler(random_state=23)\n",
        "  return rus.fit_resample(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X403mTc63eU",
        "colab_type": "text"
      },
      "source": [
        "## Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxmxQciRAbkN",
        "colab_type": "code",
        "outputId": "7ed617ef-3639-47f5-fbfe-27820d4601ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVOfxVy2_Z8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sparse_bow_X = sparse.load_npz(\"/content/gdrive/My Drive/code-clones/csv/bagofwords_vectors_X.npz\")\n",
        "sparse_bow_y = sparse.load_npz(\"/content/gdrive/My Drive/code-clones/csv/bagofwords_vectors_y.npz\").T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YnUcesCfFym",
        "colab_type": "code",
        "outputId": "d23863d7-14c0-446f-e04e-88df15ea8288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sparse_bow_y.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19990, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIdMIIrYf6Db",
        "colab_type": "code",
        "outputId": "54b70317-56c2-4f5e-f582-831bb2b8f4a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sparse_bow_X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19990, 52736)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIhpsRnuQQJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_resampled, y_resampled = resample(sparse_bow_X, sparse_bow_y.toarray())\n",
        "#print(sorted(Counter(y_resampled.T).items()))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=23)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5zY9EsYoZwX",
        "colab_type": "code",
        "outputId": "557dd17e-8ed5-485f-e81d-33ab88b5cf09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!git clone https://github.com/hyperopt/hyperopt-sklearn\n",
        "%cd hyperopt-sklearn\n",
        "!pip install -e ."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hyperopt-sklearn'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)   \u001b[K\rremote: Counting objects:  28% (2/7)   \u001b[K\rremote: Counting objects:  42% (3/7)   \u001b[K\rremote: Counting objects:  57% (4/7)   \u001b[K\rremote: Counting objects:  71% (5/7)   \u001b[K\rremote: Counting objects:  85% (6/7)   \u001b[K\rremote: Counting objects: 100% (7/7)   \u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  14% (1/7)   \u001b[K\rremote: Compressing objects:  28% (2/7)   \u001b[K\rremote: Compressing objects:  42% (3/7)   \u001b[K\rremote: Compressing objects:  57% (4/7)   \u001b[K\rremote: Compressing objects:  71% (5/7)   \u001b[K\rremote: Compressing objects:  85% (6/7)   \u001b[K\rremote: Compressing objects: 100% (7/7)   \u001b[K\rremote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "Receiving objects:   0% (1/1171)   \rReceiving objects:   1% (12/1171)   \rReceiving objects:   2% (24/1171)   \rReceiving objects:   3% (36/1171)   \rReceiving objects:   4% (47/1171)   \rReceiving objects:   5% (59/1171)   \rReceiving objects:   6% (71/1171)   \rReceiving objects:   7% (82/1171)   \rReceiving objects:   8% (94/1171)   \rReceiving objects:   9% (106/1171)   \rReceiving objects:  10% (118/1171)   \rReceiving objects:  11% (129/1171)   \rReceiving objects:  12% (141/1171)   \rReceiving objects:  13% (153/1171)   \rReceiving objects:  14% (164/1171)   \rReceiving objects:  15% (176/1171)   \rReceiving objects:  16% (188/1171)   \rReceiving objects:  17% (200/1171)   \rReceiving objects:  18% (211/1171)   \rReceiving objects:  19% (223/1171)   \rReceiving objects:  20% (235/1171)   \rReceiving objects:  21% (246/1171)   \rReceiving objects:  22% (258/1171)   \rReceiving objects:  23% (270/1171)   \rReceiving objects:  24% (282/1171)   \rReceiving objects:  25% (293/1171)   \rReceiving objects:  26% (305/1171)   \rReceiving objects:  27% (317/1171)   \rReceiving objects:  28% (328/1171)   \rReceiving objects:  29% (340/1171)   \rReceiving objects:  30% (352/1171)   \rReceiving objects:  31% (364/1171)   \rReceiving objects:  32% (375/1171)   \rReceiving objects:  33% (387/1171)   \rReceiving objects:  34% (399/1171)   \rReceiving objects:  35% (410/1171)   \rReceiving objects:  36% (422/1171)   \rReceiving objects:  37% (434/1171)   \rReceiving objects:  38% (445/1171)   \rReceiving objects:  39% (457/1171)   \rReceiving objects:  40% (469/1171)   \rReceiving objects:  41% (481/1171)   \rReceiving objects:  42% (492/1171)   \rReceiving objects:  43% (504/1171)   \rReceiving objects:  44% (516/1171)   \rReceiving objects:  45% (527/1171)   \rReceiving objects:  46% (539/1171)   \rReceiving objects:  47% (551/1171)   \rReceiving objects:  48% (563/1171)   \rReceiving objects:  49% (574/1171)   \rReceiving objects:  50% (586/1171)   \rReceiving objects:  51% (598/1171)   \rReceiving objects:  52% (609/1171)   \rReceiving objects:  53% (621/1171)   \rReceiving objects:  54% (633/1171)   \rReceiving objects:  55% (645/1171)   \rReceiving objects:  56% (656/1171)   \rReceiving objects:  57% (668/1171)   \rReceiving objects:  58% (680/1171)   \rReceiving objects:  59% (691/1171)   \rReceiving objects:  60% (703/1171)   \rReceiving objects:  61% (715/1171)   \rReceiving objects:  62% (727/1171)   \rReceiving objects:  63% (738/1171)   \rReceiving objects:  64% (750/1171)   \rReceiving objects:  65% (762/1171)   \rReceiving objects:  66% (773/1171)   \rReceiving objects:  67% (785/1171)   \rReceiving objects:  68% (797/1171)   \rReceiving objects:  69% (808/1171)   \rReceiving objects:  70% (820/1171)   \rReceiving objects:  71% (832/1171)   \rReceiving objects:  72% (844/1171)   \rReceiving objects:  73% (855/1171)   \rReceiving objects:  74% (867/1171)   \rReceiving objects:  75% (879/1171)   \rReceiving objects:  76% (890/1171)   \rReceiving objects:  77% (902/1171)   \rReceiving objects:  78% (914/1171)   \rReceiving objects:  79% (926/1171)   \rremote: Total 1171 (delta 1), reused 4 (delta 0), pack-reused 1164\n",
            "Receiving objects:  80% (937/1171)   \rReceiving objects:  81% (949/1171)   \rReceiving objects:  82% (961/1171)   \rReceiving objects:  83% (972/1171)   \rReceiving objects:  84% (984/1171)   \rReceiving objects:  85% (996/1171)   \rReceiving objects:  86% (1008/1171)   \rReceiving objects:  87% (1019/1171)   \rReceiving objects:  88% (1031/1171)   \rReceiving objects:  89% (1043/1171)   \rReceiving objects:  90% (1054/1171)   \rReceiving objects:  91% (1066/1171)   \rReceiving objects:  92% (1078/1171)   \rReceiving objects:  93% (1090/1171)   \rReceiving objects:  94% (1101/1171)   \rReceiving objects:  95% (1113/1171)   \rReceiving objects:  96% (1125/1171)   \rReceiving objects:  97% (1136/1171)   \rReceiving objects:  98% (1148/1171)   \rReceiving objects:  99% (1160/1171)   \rReceiving objects: 100% (1171/1171)   \rReceiving objects: 100% (1171/1171), 2.00 MiB | 19.90 MiB/s, done.\n",
            "Resolving deltas:   0% (0/708)   \rResolving deltas:   1% (8/708)   \rResolving deltas:   2% (20/708)   \rResolving deltas:   4% (29/708)   \rResolving deltas:   7% (51/708)   \rResolving deltas:   8% (62/708)   \rResolving deltas:   9% (67/708)   \rResolving deltas:  10% (72/708)   \rResolving deltas:  12% (91/708)   \rResolving deltas:  13% (94/708)   \rResolving deltas:  17% (123/708)   \rResolving deltas:  18% (130/708)   \rResolving deltas:  19% (138/708)   \rResolving deltas:  20% (144/708)   \rResolving deltas:  21% (155/708)   \rResolving deltas:  22% (156/708)   \rResolving deltas:  26% (186/708)   \rResolving deltas:  29% (207/708)   \rResolving deltas:  41% (293/708)   \rResolving deltas:  42% (298/708)   \rResolving deltas:  43% (305/708)   \rResolving deltas:  44% (314/708)   \rResolving deltas:  45% (319/708)   \rResolving deltas:  50% (361/708)   \rResolving deltas:  58% (416/708)   \rResolving deltas:  59% (423/708)   \rResolving deltas:  60% (425/708)   \rResolving deltas:  61% (432/708)   \rResolving deltas:  62% (444/708)   \rResolving deltas:  63% (447/708)   \rResolving deltas:  65% (465/708)   \rResolving deltas:  66% (468/708)   \rResolving deltas:  67% (479/708)   \rResolving deltas:  74% (530/708)   \rResolving deltas:  77% (549/708)   \rResolving deltas:  79% (562/708)   \rResolving deltas:  80% (571/708)   \rResolving deltas:  84% (596/708)   \rResolving deltas:  85% (605/708)   \rResolving deltas:  86% (611/708)   \rResolving deltas:  90% (639/708)   \rResolving deltas:  91% (650/708)   \rResolving deltas:  92% (653/708)   \rResolving deltas:  93% (659/708)   \rResolving deltas:  96% (681/708)   \rResolving deltas:  99% (704/708)   \rResolving deltas: 100% (708/708)   \rResolving deltas: 100% (708/708), done.\n",
            "/content/hyperopt-sklearn\n",
            "Obtaining file:///content/hyperopt-sklearn\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.1.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.20.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (1.12.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (3.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (4.28.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hpsklearn==0.0.3) (4.4.0)\n",
            "Installing collected packages: hpsklearn\n",
            "  Running setup.py develop for hpsklearn\n",
            "Successfully installed hpsklearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-9j_qPWolyb",
        "colab_type": "code",
        "outputId": "60dac06b-b55b-4083-cfc4-ed39b9228496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from hpsklearn import HyperoptEstimator, any_sparse_classifier, any_classifier\n",
        "from hyperopt import tpe"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARN: OMP_NUM_THREADS=None =>\n",
            "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh2Hady7f4Wl",
        "colab_type": "text"
      },
      "source": [
        "## Сustom loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc2BTds0bwu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_fnr_fpr(y_target, y_prediction):\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  n = len(y_target)\n",
        "  for i in range(n):\n",
        "    if y_prediction[i] == 1 and y_target[i] == 0:\n",
        "      fp += 1\n",
        "    if y_prediction[i] == 0 and y_target[i] == 1:\n",
        "      fn += 1\n",
        "  return (fn / n, fp / n) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoeNibZZUjWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_target, y_prediction):\n",
        "  k_fn = 1\n",
        "  k_fp = 10\n",
        "  n = len(y_target)\n",
        "  (fnr, fpr) = calc_fnr_fpr(y_target, y_prediction)\n",
        "  return k_fn * fnr + k_fp * fpr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl1lbF9vZ63J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hyperopt_custom_loss_estimator(X_train, y_train, sparse=True):\n",
        "  classifier = any_sparse_classifier('clf') if sparse else any_classifier('clf')\n",
        "  estim = HyperoptEstimator(classifier=classifier,\n",
        "                          preprocessing=[],\n",
        "                          algo=tpe.suggest, \n",
        "                          trial_timeout=300,\n",
        "                          loss_fn=custom_loss,\n",
        "                          seed=23)\n",
        "  estim.fit(X_train, y_train)\n",
        "  return estim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc5sI_mSf_SY",
        "colab_type": "text"
      },
      "source": [
        "## Custom loss bow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGcvcNoAdIXC",
        "colab_type": "code",
        "outputId": "a77fc8d3-360a-4a13-eb0f-41d475e3888a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "estim = hyperopt_custom_loss_estimator(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [01:10<00:00, 70.92s/it, best loss: 1.7004297114794351]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.02it/s, best loss: 1.7004297114794351]\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.25it/s, best loss: 1.4223449969306323]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.41it/s, best loss: 1.4223449969306323]\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.30s/it, best loss: 1.4223449969306323]\n",
            "100%|██████████| 1/1 [01:09<00:00, 69.96s/it, best loss: 1.4223449969306323]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.71it/s, best loss: 1.4223449969306323]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.44it/s, best loss: 1.4223449969306323]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.54it/s, best loss: 1.4223449969306323]\n",
            "100%|██████████| 1/1 [00:00<00:00, 16.27it/s, best loss: 1.4223449969306323]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRNxsNU79_9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = estim.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah1fMDLH97_6",
        "colab_type": "code",
        "outputId": "3fb4c1d0-9251-4562-869b-f984f84eaf5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "calc_fnr_fpr(y_test, y_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1285451197053407, 0.1406998158379374)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiQw6N9x-BhB",
        "colab_type": "code",
        "outputId": "8615c3bf-cd06-4a9c-cd84-8c011fee2148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "printMetrics(y_test, y_pred)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: \n",
            "0.7307550644567219\n",
            "\n",
            "precision: \n",
            "0.730225988700565\n",
            "\n",
            "recall: \n",
            "0.74765003615329\n",
            "\n",
            "roc auc: \n",
            "0.7304316246832515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KexPm_aOsom3",
        "colab_type": "code",
        "outputId": "7dc0a8ec-647b-4c86-f3aa-1104a49e069e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "estim.best_model()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ex_preprocs': (),\n",
              " 'learner': SGDClassifier(alpha=0.06118428364662971, average=False, class_weight=None,\n",
              "        early_stopping=False, epsilon=0.1, eta0=0.0003970052556398526,\n",
              "        fit_intercept=True, l1_ratio=0.5022724095962902,\n",
              "        learning_rate='constant', loss='log', max_iter=158684350.0,\n",
              "        n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='l2',\n",
              "        power_t=0.907051629874976, random_state=0, shuffle=True,\n",
              "        tol=0.006308140398304822, validation_fraction=0.1, verbose=False,\n",
              "        warm_start=False),\n",
              " 'preprocs': ()}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0SpZmVTD1Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thr = 0.5\n",
        "y_prob = [y[1] for y in estim.best_model()['learner'].predict_proba(X_test)]\n",
        "y_pred = [int(y >= thr) for y in y_prob]\n",
        "_, fpr = calc_fnr_fpr(y_test, y_pred)\n",
        "while fpr - 0.10 >= 0.005:\n",
        "  thr += 0.0005\n",
        "  y_pred = [int(y >= thr) for y in y_prob]\n",
        "  _, fpr = calc_fnr_fpr(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0lmuDeyEKIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1731ddc4-86f2-4b05-f285-d9cd3e178649"
      },
      "source": [
        "thr"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5199999999999978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ae8OHtEEMNZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3941cb0-4f28-4825-cf29-12dfeee1f1b7"
      },
      "source": [
        "calc_fnr_fpr(y_test, y_pred)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.17605893186003682, 0.10460405156537753)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D29_2_V8EQ_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0b47b05b-2278-4281-f647-a789e02a7590"
      },
      "source": [
        "printMetrics(y_test, y_pred)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: \n",
            "0.7193370165745856\n",
            "\n",
            "precision: \n",
            "0.7611438183347351\n",
            "\n",
            "recall: \n",
            "0.6543745480838756\n",
            "\n",
            "roc auc: \n",
            "0.7205806674353312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxsBu2hF68Ps",
        "colab_type": "text"
      },
      "source": [
        "## code2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SzghHhF6_Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_csv(\"/content/gdrive/My Drive/code-clones/csv/lwjgl3_code2vec_vectors1.csv\")\n",
        "df2 = pd.read_csv(\"/content/gdrive/My Drive/code-clones/csv/lwjgl3_code2vec_vectors2.csv\")\n",
        "df3 = pd.read_csv(\"/content/gdrive/My Drive/code-clones/csv/lwjgl_code2vec_vectors.csv\")\n",
        "df4 = pd.read_csv(\"/content/gdrive/My Drive/code-clones/csv/spring_code2vec_vectors.csv\")\n",
        "df5 = pd.read_csv(\"/content/gdrive/My Drive/code-clones/csv/jenkins_code2vec_vectors.csv\")\n",
        "df6 = pd.read_csv(\"/content/gdrive/My Drive/code-clones/csv/rxjava_code2vec_vectors.csv\")\n",
        "df_c2v = pd.concat([df1, df2, df3, df4, df5, df6], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eaI3BuZ7eEC",
        "colab_type": "code",
        "outputId": "46841b17-2703-4e49-e7f3-40a98996d87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "df_c2v.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exp</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "      <th>349</th>\n",
              "      <th>350</th>\n",
              "      <th>351</th>\n",
              "      <th>352</th>\n",
              "      <th>353</th>\n",
              "      <th>354</th>\n",
              "      <th>355</th>\n",
              "      <th>356</th>\n",
              "      <th>357</th>\n",
              "      <th>358</th>\n",
              "      <th>359</th>\n",
              "      <th>360</th>\n",
              "      <th>361</th>\n",
              "      <th>362</th>\n",
              "      <th>363</th>\n",
              "      <th>364</th>\n",
              "      <th>365</th>\n",
              "      <th>366</th>\n",
              "      <th>367</th>\n",
              "      <th>368</th>\n",
              "      <th>369</th>\n",
              "      <th>370</th>\n",
              "      <th>371</th>\n",
              "      <th>372</th>\n",
              "      <th>373</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.708866</td>\n",
              "      <td>-0.139283</td>\n",
              "      <td>0.790398</td>\n",
              "      <td>0.880303</td>\n",
              "      <td>0.291317</td>\n",
              "      <td>0.553174</td>\n",
              "      <td>0.823598</td>\n",
              "      <td>-0.693108</td>\n",
              "      <td>-0.379951</td>\n",
              "      <td>-0.536196</td>\n",
              "      <td>-0.057756</td>\n",
              "      <td>-0.763562</td>\n",
              "      <td>-0.781960</td>\n",
              "      <td>-0.448249</td>\n",
              "      <td>-0.533357</td>\n",
              "      <td>-0.451522</td>\n",
              "      <td>-0.065547</td>\n",
              "      <td>0.545325</td>\n",
              "      <td>0.905961</td>\n",
              "      <td>0.846379</td>\n",
              "      <td>0.947172</td>\n",
              "      <td>-0.874068</td>\n",
              "      <td>0.936903</td>\n",
              "      <td>-0.440319</td>\n",
              "      <td>0.009643</td>\n",
              "      <td>-0.558544</td>\n",
              "      <td>0.288042</td>\n",
              "      <td>-0.060373</td>\n",
              "      <td>0.068816</td>\n",
              "      <td>-0.541809</td>\n",
              "      <td>-0.713808</td>\n",
              "      <td>0.880594</td>\n",
              "      <td>-0.628212</td>\n",
              "      <td>-0.872760</td>\n",
              "      <td>0.714413</td>\n",
              "      <td>-0.542334</td>\n",
              "      <td>0.740742</td>\n",
              "      <td>-0.198978</td>\n",
              "      <td>-0.450086</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075166</td>\n",
              "      <td>-0.686472</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.886230</td>\n",
              "      <td>0.070973</td>\n",
              "      <td>0.990748</td>\n",
              "      <td>0.556059</td>\n",
              "      <td>-0.979709</td>\n",
              "      <td>0.716640</td>\n",
              "      <td>-0.159755</td>\n",
              "      <td>-0.584313</td>\n",
              "      <td>0.863680</td>\n",
              "      <td>-0.305081</td>\n",
              "      <td>0.005122</td>\n",
              "      <td>0.208050</td>\n",
              "      <td>-0.919549</td>\n",
              "      <td>0.481194</td>\n",
              "      <td>-0.905497</td>\n",
              "      <td>0.054141</td>\n",
              "      <td>0.132897</td>\n",
              "      <td>-0.831053</td>\n",
              "      <td>0.891648</td>\n",
              "      <td>0.524972</td>\n",
              "      <td>-0.797217</td>\n",
              "      <td>0.006505</td>\n",
              "      <td>-0.805470</td>\n",
              "      <td>0.439665</td>\n",
              "      <td>-0.932609</td>\n",
              "      <td>-0.972230</td>\n",
              "      <td>0.444506</td>\n",
              "      <td>0.409421</td>\n",
              "      <td>-0.743124</td>\n",
              "      <td>-0.406415</td>\n",
              "      <td>0.348190</td>\n",
              "      <td>-0.722999</td>\n",
              "      <td>0.883331</td>\n",
              "      <td>0.975385</td>\n",
              "      <td>0.811376</td>\n",
              "      <td>0.529098</td>\n",
              "      <td>-0.580801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.457570</td>\n",
              "      <td>0.465724</td>\n",
              "      <td>0.049870</td>\n",
              "      <td>0.329546</td>\n",
              "      <td>0.185015</td>\n",
              "      <td>-0.367061</td>\n",
              "      <td>0.646942</td>\n",
              "      <td>0.066054</td>\n",
              "      <td>-0.377213</td>\n",
              "      <td>0.211417</td>\n",
              "      <td>-0.618707</td>\n",
              "      <td>0.051697</td>\n",
              "      <td>-0.098210</td>\n",
              "      <td>0.367054</td>\n",
              "      <td>-0.714161</td>\n",
              "      <td>-0.273630</td>\n",
              "      <td>0.390221</td>\n",
              "      <td>0.230662</td>\n",
              "      <td>0.526845</td>\n",
              "      <td>-0.471009</td>\n",
              "      <td>-0.086963</td>\n",
              "      <td>0.647146</td>\n",
              "      <td>-0.149217</td>\n",
              "      <td>0.850062</td>\n",
              "      <td>0.063569</td>\n",
              "      <td>-0.201275</td>\n",
              "      <td>-0.523791</td>\n",
              "      <td>0.217598</td>\n",
              "      <td>0.393475</td>\n",
              "      <td>-0.242300</td>\n",
              "      <td>0.048727</td>\n",
              "      <td>0.385479</td>\n",
              "      <td>-0.608135</td>\n",
              "      <td>-0.076953</td>\n",
              "      <td>0.053418</td>\n",
              "      <td>0.257176</td>\n",
              "      <td>-0.541758</td>\n",
              "      <td>-0.838411</td>\n",
              "      <td>0.164181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.243302</td>\n",
              "      <td>-0.210837</td>\n",
              "      <td>-0.267095</td>\n",
              "      <td>-0.873269</td>\n",
              "      <td>-0.082603</td>\n",
              "      <td>-0.095414</td>\n",
              "      <td>-0.132618</td>\n",
              "      <td>-0.470093</td>\n",
              "      <td>-0.649802</td>\n",
              "      <td>0.424356</td>\n",
              "      <td>0.059514</td>\n",
              "      <td>-0.261998</td>\n",
              "      <td>-0.033176</td>\n",
              "      <td>0.049180</td>\n",
              "      <td>0.144208</td>\n",
              "      <td>0.056680</td>\n",
              "      <td>0.152013</td>\n",
              "      <td>-0.175859</td>\n",
              "      <td>-0.114169</td>\n",
              "      <td>0.529386</td>\n",
              "      <td>0.405167</td>\n",
              "      <td>0.616029</td>\n",
              "      <td>-0.260005</td>\n",
              "      <td>-0.537304</td>\n",
              "      <td>0.111804</td>\n",
              "      <td>0.100389</td>\n",
              "      <td>0.545154</td>\n",
              "      <td>-0.169261</td>\n",
              "      <td>0.353477</td>\n",
              "      <td>0.224362</td>\n",
              "      <td>0.422311</td>\n",
              "      <td>0.542749</td>\n",
              "      <td>0.726254</td>\n",
              "      <td>0.081205</td>\n",
              "      <td>-0.139942</td>\n",
              "      <td>-0.282454</td>\n",
              "      <td>0.584696</td>\n",
              "      <td>0.316820</td>\n",
              "      <td>0.038821</td>\n",
              "      <td>-0.080841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.674882</td>\n",
              "      <td>-0.227605</td>\n",
              "      <td>-0.051460</td>\n",
              "      <td>0.322587</td>\n",
              "      <td>0.113033</td>\n",
              "      <td>-0.206298</td>\n",
              "      <td>0.618875</td>\n",
              "      <td>-0.831079</td>\n",
              "      <td>0.467831</td>\n",
              "      <td>0.223961</td>\n",
              "      <td>-0.474329</td>\n",
              "      <td>-0.135923</td>\n",
              "      <td>0.431246</td>\n",
              "      <td>-0.218008</td>\n",
              "      <td>-0.649191</td>\n",
              "      <td>0.012374</td>\n",
              "      <td>0.336949</td>\n",
              "      <td>0.886156</td>\n",
              "      <td>0.454673</td>\n",
              "      <td>-0.639669</td>\n",
              "      <td>0.443773</td>\n",
              "      <td>0.031497</td>\n",
              "      <td>0.345675</td>\n",
              "      <td>0.482762</td>\n",
              "      <td>-0.693035</td>\n",
              "      <td>0.416126</td>\n",
              "      <td>-0.515968</td>\n",
              "      <td>0.172227</td>\n",
              "      <td>0.217237</td>\n",
              "      <td>-0.311850</td>\n",
              "      <td>-0.614717</td>\n",
              "      <td>0.240569</td>\n",
              "      <td>-0.554820</td>\n",
              "      <td>-0.054012</td>\n",
              "      <td>-0.354445</td>\n",
              "      <td>-0.449013</td>\n",
              "      <td>-0.176670</td>\n",
              "      <td>-0.092752</td>\n",
              "      <td>-0.221199</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175787</td>\n",
              "      <td>-0.184850</td>\n",
              "      <td>-0.531791</td>\n",
              "      <td>-0.455446</td>\n",
              "      <td>-0.020367</td>\n",
              "      <td>0.270404</td>\n",
              "      <td>0.041985</td>\n",
              "      <td>-0.550160</td>\n",
              "      <td>0.767969</td>\n",
              "      <td>0.171719</td>\n",
              "      <td>-0.247429</td>\n",
              "      <td>-0.261586</td>\n",
              "      <td>-0.072140</td>\n",
              "      <td>-0.336018</td>\n",
              "      <td>-0.227835</td>\n",
              "      <td>-0.287362</td>\n",
              "      <td>-0.423872</td>\n",
              "      <td>-0.743692</td>\n",
              "      <td>0.063031</td>\n",
              "      <td>0.646673</td>\n",
              "      <td>-0.507511</td>\n",
              "      <td>0.666606</td>\n",
              "      <td>-0.274423</td>\n",
              "      <td>0.246878</td>\n",
              "      <td>-0.009419</td>\n",
              "      <td>-0.132733</td>\n",
              "      <td>0.432687</td>\n",
              "      <td>0.648385</td>\n",
              "      <td>0.087229</td>\n",
              "      <td>-0.328465</td>\n",
              "      <td>0.380035</td>\n",
              "      <td>-0.358241</td>\n",
              "      <td>0.168523</td>\n",
              "      <td>-0.115633</td>\n",
              "      <td>0.013167</td>\n",
              "      <td>-0.600655</td>\n",
              "      <td>-0.152489</td>\n",
              "      <td>0.309746</td>\n",
              "      <td>0.104927</td>\n",
              "      <td>-0.338480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238518</td>\n",
              "      <td>0.239017</td>\n",
              "      <td>-0.329432</td>\n",
              "      <td>0.076081</td>\n",
              "      <td>0.674525</td>\n",
              "      <td>0.240891</td>\n",
              "      <td>-0.138851</td>\n",
              "      <td>0.377708</td>\n",
              "      <td>-0.052835</td>\n",
              "      <td>0.758993</td>\n",
              "      <td>0.212176</td>\n",
              "      <td>0.319090</td>\n",
              "      <td>0.772388</td>\n",
              "      <td>-0.185795</td>\n",
              "      <td>0.141485</td>\n",
              "      <td>-0.263851</td>\n",
              "      <td>-0.114226</td>\n",
              "      <td>0.478966</td>\n",
              "      <td>-0.436920</td>\n",
              "      <td>-0.188591</td>\n",
              "      <td>-0.345383</td>\n",
              "      <td>0.206126</td>\n",
              "      <td>-0.520585</td>\n",
              "      <td>0.897969</td>\n",
              "      <td>0.783976</td>\n",
              "      <td>0.424795</td>\n",
              "      <td>0.498398</td>\n",
              "      <td>-0.557342</td>\n",
              "      <td>0.319309</td>\n",
              "      <td>-0.687786</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>0.692565</td>\n",
              "      <td>0.063520</td>\n",
              "      <td>0.564135</td>\n",
              "      <td>0.445329</td>\n",
              "      <td>-0.448139</td>\n",
              "      <td>-0.636677</td>\n",
              "      <td>0.653752</td>\n",
              "      <td>-0.661554</td>\n",
              "      <td>...</td>\n",
              "      <td>0.373130</td>\n",
              "      <td>-0.401377</td>\n",
              "      <td>-0.644872</td>\n",
              "      <td>0.041106</td>\n",
              "      <td>0.609853</td>\n",
              "      <td>-0.099505</td>\n",
              "      <td>0.522919</td>\n",
              "      <td>-0.703145</td>\n",
              "      <td>0.073218</td>\n",
              "      <td>-0.380949</td>\n",
              "      <td>-0.728012</td>\n",
              "      <td>-0.726868</td>\n",
              "      <td>-0.303032</td>\n",
              "      <td>-0.133776</td>\n",
              "      <td>0.549605</td>\n",
              "      <td>-0.556467</td>\n",
              "      <td>0.017998</td>\n",
              "      <td>-0.530820</td>\n",
              "      <td>-0.106090</td>\n",
              "      <td>-0.760480</td>\n",
              "      <td>-0.038897</td>\n",
              "      <td>0.251707</td>\n",
              "      <td>0.725792</td>\n",
              "      <td>0.145969</td>\n",
              "      <td>0.424751</td>\n",
              "      <td>-0.584596</td>\n",
              "      <td>-0.767587</td>\n",
              "      <td>0.301838</td>\n",
              "      <td>0.746892</td>\n",
              "      <td>-0.455481</td>\n",
              "      <td>-0.629672</td>\n",
              "      <td>-0.818671</td>\n",
              "      <td>-0.240460</td>\n",
              "      <td>0.834071</td>\n",
              "      <td>-0.167629</td>\n",
              "      <td>-0.331171</td>\n",
              "      <td>-0.589584</td>\n",
              "      <td>0.668989</td>\n",
              "      <td>0.260057</td>\n",
              "      <td>0.465806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.261068</td>\n",
              "      <td>-0.683279</td>\n",
              "      <td>-0.386828</td>\n",
              "      <td>0.031994</td>\n",
              "      <td>-0.891767</td>\n",
              "      <td>0.202983</td>\n",
              "      <td>-0.022529</td>\n",
              "      <td>0.667178</td>\n",
              "      <td>0.515003</td>\n",
              "      <td>0.826141</td>\n",
              "      <td>-0.176847</td>\n",
              "      <td>-0.039715</td>\n",
              "      <td>-0.733276</td>\n",
              "      <td>0.443135</td>\n",
              "      <td>-0.023443</td>\n",
              "      <td>-0.327092</td>\n",
              "      <td>-0.362199</td>\n",
              "      <td>0.233987</td>\n",
              "      <td>0.319233</td>\n",
              "      <td>0.299280</td>\n",
              "      <td>-0.234696</td>\n",
              "      <td>0.303305</td>\n",
              "      <td>0.170403</td>\n",
              "      <td>-0.224727</td>\n",
              "      <td>0.483681</td>\n",
              "      <td>-0.372073</td>\n",
              "      <td>0.648301</td>\n",
              "      <td>-0.407349</td>\n",
              "      <td>-0.432478</td>\n",
              "      <td>0.606037</td>\n",
              "      <td>-0.137597</td>\n",
              "      <td>0.223075</td>\n",
              "      <td>0.147892</td>\n",
              "      <td>-0.423443</td>\n",
              "      <td>-0.441040</td>\n",
              "      <td>-0.332034</td>\n",
              "      <td>-0.342627</td>\n",
              "      <td>0.125737</td>\n",
              "      <td>-0.407850</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.610979</td>\n",
              "      <td>-0.784399</td>\n",
              "      <td>0.278932</td>\n",
              "      <td>-0.380384</td>\n",
              "      <td>-0.457574</td>\n",
              "      <td>0.915914</td>\n",
              "      <td>0.290403</td>\n",
              "      <td>-0.275704</td>\n",
              "      <td>-0.058648</td>\n",
              "      <td>0.762267</td>\n",
              "      <td>-0.227620</td>\n",
              "      <td>0.422656</td>\n",
              "      <td>0.326875</td>\n",
              "      <td>-0.433874</td>\n",
              "      <td>0.615914</td>\n",
              "      <td>0.239106</td>\n",
              "      <td>-0.050791</td>\n",
              "      <td>-0.410500</td>\n",
              "      <td>-0.014974</td>\n",
              "      <td>0.270726</td>\n",
              "      <td>-0.353269</td>\n",
              "      <td>0.280647</td>\n",
              "      <td>-0.001562</td>\n",
              "      <td>0.455043</td>\n",
              "      <td>0.148662</td>\n",
              "      <td>0.320710</td>\n",
              "      <td>-0.886484</td>\n",
              "      <td>0.124052</td>\n",
              "      <td>0.072454</td>\n",
              "      <td>0.706325</td>\n",
              "      <td>-0.393192</td>\n",
              "      <td>0.125753</td>\n",
              "      <td>0.020193</td>\n",
              "      <td>0.403067</td>\n",
              "      <td>-0.779176</td>\n",
              "      <td>0.066885</td>\n",
              "      <td>0.953279</td>\n",
              "      <td>-0.108147</td>\n",
              "      <td>0.251376</td>\n",
              "      <td>-0.543750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 385 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   exp         1         2         3  ...       381       382       383       384\n",
              "0  0.0  0.708866 -0.139283  0.790398  ...  0.975385  0.811376  0.529098 -0.580801\n",
              "1  0.0  0.457570  0.465724  0.049870  ...  0.584696  0.316820  0.038821 -0.080841\n",
              "2  0.0  0.674882 -0.227605 -0.051460  ... -0.152489  0.309746  0.104927 -0.338480\n",
              "3  0.0  0.238518  0.239017 -0.329432  ... -0.589584  0.668989  0.260057  0.465806\n",
              "4  0.0 -0.261068 -0.683279 -0.386828  ...  0.953279 -0.108147  0.251376 -0.543750\n",
              "\n",
              "[5 rows x 385 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7XJrokKgKm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df_c2v['exp']\n",
        "X = df_c2v.drop('exp', 1)\n",
        "X_resampled, y_resampled = resample(X, y)\n",
        "#print(sorted(Counter(y_resampled.T).items()))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=23)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSnjd00ngR6N",
        "colab_type": "text"
      },
      "source": [
        "## Custom loss code2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQlB6Y8wgRoi",
        "colab_type": "code",
        "outputId": "a04b6b28-e76e-4928-93ff-52f4ef0b8874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "estim = hyperopt_custom_loss_estimator(X_train, y_train, sparse=False)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:13<00:00, 13.23s/it, best loss: 2.9465317919075145]\n",
            "100%|██████████| 1/1 [00:11<00:00, 11.01s/it, best loss: 2.79335260115607]\n",
            "100%|██████████| 1/1 [00:18<00:00, 18.91s/it, best loss: 2.79335260115607]\n",
            "100%|██████████| 1/1 [01:14<00:00, 74.96s/it, best loss: 2.79335260115607]\n",
            "100%|██████████| 1/1 [00:12<00:00, 12.51s/it, best loss: 2.0209537572254335]\n",
            "100%|██████████| 1/1 [00:16<00:00, 16.33s/it, best loss: 2.0209537572254335]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.95it/s, best loss: 1.9342485549132948]\n",
            "100%|██████████| 1/1 [01:34<00:00, 94.50s/it, best loss: 1.9342485549132948]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.46s/it, best loss: 1.8229768786127167]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.90s/it, best loss: 1.8229768786127167]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0eoZoCmLy2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = estim.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLp8_fzeL16J",
        "colab_type": "code",
        "outputId": "17d17bd9-d95d-4332-8836-13b0ebf7bb63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "calc_fnr_fpr(y_test, y_pred)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.07368877329865627, 0.19592544429995665)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4XDrmHjL58U",
        "colab_type": "code",
        "outputId": "635aefb2-ff0f-48bc-86fb-f33db9010cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "printMetrics(y_test, y_pred)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: \n",
            "0.7303857824013871\n",
            "\n",
            "precision: \n",
            "0.6861111111111111\n",
            "\n",
            "recall: \n",
            "0.853195164075993\n",
            "\n",
            "roc auc: \n",
            "0.7299048057107556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw60AcKvCiKX",
        "colab_type": "code",
        "outputId": "88d845e4-32a1-4ab2-a97c-756220206246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "estim.best_model()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ex_preprocs': (),\n",
              " 'learner': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
              "               learning_rate=0.005891891362147046, loss='deviance',\n",
              "               max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
              "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "               min_samples_leaf=8, min_samples_split=2,\n",
              "               min_weight_fraction_leaf=0.0, n_estimators=16,\n",
              "               n_iter_no_change=None, presort='auto', random_state=0,\n",
              "               subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
              "               verbose=0, warm_start=False),\n",
              " 'preprocs': ()}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2BqX-I-Ew83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thr = 0.5\n",
        "y_prob = [y[1] for y in estim.best_model()['learner'].predict_proba(X_test)]\n",
        "y_pred = [int(y >= thr) for y in y_prob]\n",
        "_, fpr = calc_fnr_fpr(y_test, y_pred)\n",
        "while fpr - 0.10 >= 0.005:\n",
        "  thr += 0.0005\n",
        "  y_pred = [int(y >= thr) for y in y_prob]\n",
        "  _, fpr = calc_fnr_fpr(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXpyJiaJE1a2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fb48c38-0bc0-4426-a28e-081a444f1d84"
      },
      "source": [
        "thr"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5084999999999991"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvlmyI0cE171",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0342335-7620-43ad-ebee-7c2a42003f7b"
      },
      "source": [
        "calc_fnr_fpr(y_test, y_pred)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1729518855656697, 0.10489813610749892)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnPUIbEqE6WK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "59e9c1ba-717d-4226-affd-4b678c0a87a3"
      },
      "source": [
        "printMetrics(y_test, y_pred)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: \n",
            "0.7221499783268314\n",
            "\n",
            "precision: \n",
            "0.7582417582417582\n",
            "\n",
            "recall: \n",
            "0.655440414507772\n",
            "\n",
            "roc auc: \n",
            "0.7224112429370888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5OPcTdIE6nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}